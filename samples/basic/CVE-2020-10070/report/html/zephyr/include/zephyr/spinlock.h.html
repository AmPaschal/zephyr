
<html>
<head>
<title>zephyr/include/zephyr/spinlock.h</title>
<link rel="stylesheet" type="text/css" href="../../../viewer.css">
</head>

<body>
<div class="code">
<div id="1" class="line none">    1 /*</div><div id="2" class="line none">    2  * Copyright (c) 2018 Intel Corporation.</div><div id="3" class="line none">    3  *</div><div id="4" class="line none">    4  * SPDX-License-Identifier: Apache-2.0</div><div id="5" class="line none">    5  */</div><div id="6" class="line none">    6 </div><div id="7" class="line none">    7 /**</div><div id="8" class="line none">    8  * @file</div><div id="9" class="line none">    9  * @brief Public interface for spinlocks</div><div id="10" class="line none">   10  */</div><div id="11" class="line none">   11 </div><div id="12" class="line none">   12 #ifndef <a href="spinlock.h.html#13">ZEPHYR_INCLUDE_SPINLOCK_H_</a></div><div id="13" class="line none">   13 #define <a href="spinlock.h.html#13">ZEPHYR_INCLUDE_SPINLOCK_H_</a></div><div id="14" class="line none">   14 </div><div id="15" class="line none">   15 #include &lt;errno.h&gt;</div><div id="16" class="line none">   16 #include &lt;stdbool.h&gt;</div><div id="17" class="line none">   17 </div><div id="18" class="line none">   18 #include &lt;zephyr/<a href="kernel/thread.h.html#376">arch</a>/<a href="kernel/thread.h.html#115">cpu</a>.h&gt;</div><div id="19" class="line none">   19 #include &lt;zephyr/sys/atomic.h&gt;</div><div id="20" class="line none">   20 #include &lt;zephyr/sys/__assert.h&gt;</div><div id="21" class="line none">   21 #include &lt;zephyr/sys/time_units.h&gt;</div><div id="22" class="line none">   22 </div><div id="23" class="line none">   23 #ifdef __cplusplus</div><div id="24" class="line none">   24 extern "C" {</div><div id="25" class="line none">   25 #endif</div><div id="26" class="line none">   26 </div><div id="27" class="line none">   27 /**</div><div id="28" class="line none">   28  * @brief Spinlock APIs</div><div id="29" class="line none">   29  * @defgroup spinlock_apis Spinlock APIs</div><div id="30" class="line none">   30  * @ingroup kernel_apis</div><div id="31" class="line none">   31  * @{</div><div id="32" class="line none">   32  */</div><div id="33" class="line none">   33 </div><div id="34" class="line none">   34 struct <a href="spinlock.h.html#34">z_spinlock_key</a> {</div><div id="35" class="line none">   35         int <a href="spinlock.h.html#35">key</a>;</div><div id="36" class="line none">   36 };</div><div id="37" class="line none">   37 </div><div id="38" class="line none">   38 /**</div><div id="39" class="line none">   39  * @brief Kernel Spin Lock</div><div id="40" class="line none">   40  *</div><div id="41" class="line none">   41  * This struct defines a spin lock record on which CPUs can wait with</div><div id="42" class="line none">   42  * k_spin_lock().  Any number of spinlocks may be defined in</div><div id="43" class="line none">   43  * application code.</div><div id="44" class="line none">   44  */</div><div id="45" class="line none">   45 struct <a href="spinlock.h.html#45">k_spinlock</a> {</div><div id="46" class="line none">   46 /**</div><div id="47" class="line none">   47  * @cond INTERNAL_HIDDEN</div><div id="48" class="line none">   48  */</div><div id="49" class="line none">   49 #ifdef CONFIG_SMP</div><div id="50" class="line none">   50 #ifdef CONFIG_TICKET_SPINLOCKS</div><div id="51" class="line none">   51         /*</div><div id="52" class="line none">   52          * Ticket spinlocks are conceptually two atomic variables,</div><div id="53" class="line none">   53          * one indicating the current FIFO head (spinlock owner),</div><div id="54" class="line none">   54          * and the other indicating the current FIFO tail.</div><div id="55" class="line none">   55          * Spinlock is acquired in the following manner:</div><div id="56" class="line none">   56          * - current FIFO tail value is atomically incremented while it's</div><div id="57" class="line none">   57          *   original value is saved as a "ticket"</div><div id="58" class="line none">   58          * - we spin until the FIFO head becomes equal to the ticket value</div><div id="59" class="line none">   59          *</div><div id="60" class="line none">   60          * Spinlock is released by atomic increment of the FIFO head</div><div id="61" class="line none">   61          */</div><div id="62" class="line none">   62         <a href="sys/atomic_types.h.html#15">atomic_t</a> <a href="kernel.h.html#2918">owner</a>;</div><div id="63" class="line none">   63         <a href="sys/atomic_types.h.html#15">atomic_t</a> <a href="spinlock.h.html#63">tail</a>;</div><div id="64" class="line none">   64 #else</div><div id="65" class="line none">   65         <a href="sys/atomic_types.h.html#15">atomic_t</a> locked;</div><div id="66" class="line none">   66 #endif /* CONFIG_TICKET_SPINLOCKS */</div><div id="67" class="line none">   67 #endif /* CONFIG_SMP */</div><div id="68" class="line none">   68 </div><div id="69" class="line none">   69 #ifdef CONFIG_SPIN_VALIDATE</div><div id="70" class="line none">   70         /* Stores the thread that holds the lock with the locking CPU</div><div id="71" class="line none">   71          * ID in the bottom two bits.</div><div id="72" class="line none">   72          */</div><div id="73" class="line none">   73         uintptr_t <a href="spinlock.h.html#73">thread_cpu</a>;</div><div id="74" class="line none">   74 #ifdef CONFIG_SPIN_LOCK_TIME_LIMIT</div><div id="75" class="line none">   75         /* Stores the time (in cycles) when a lock was taken</div><div id="76" class="line none">   76          */</div><div id="77" class="line none">   77         uint32_t <a href="spinlock.h.html#77">lock_time</a>;</div><div id="78" class="line none">   78 #endif /* CONFIG_SPIN_LOCK_TIME_LIMIT */</div><div id="79" class="line none">   79 #endif /* CONFIG_SPIN_VALIDATE */</div><div id="80" class="line none">   80 </div><div id="81" class="line none">   81 #if defined(CONFIG_CPP) &amp;&amp; !defined(CONFIG_SMP) &amp;&amp; \</div><div id="82" class="line none">   82         !defined(CONFIG_SPIN_VALIDATE)</div><div id="83" class="line none">   83         /* If CONFIG_SMP and CONFIG_SPIN_VALIDATE are both not defined</div><div id="84" class="line none">   84          * the k_spinlock struct will have no members. The result</div><div id="85" class="line none">   85          * is that in C sizeof(k_spinlock) is 0 and in C++ it is 1.</div><div id="86" class="line none">   86          *</div><div id="87" class="line none">   87          * This size difference causes problems when the k_spinlock</div><div id="88" class="line none">   88          * is embedded into another struct like k_msgq, because C and</div><div id="89" class="line none">   89          * C++ will have different ideas on the offsets of the members</div><div id="90" class="line none">   90          * that come after the k_spinlock member.</div><div id="91" class="line none">   91          *</div><div id="92" class="line none">   92          * To prevent this we add a 1 byte dummy member to k_spinlock</div><div id="93" class="line none">   93          * when the user selects C++ support and k_spinlock would</div><div id="94" class="line none">   94          * otherwise be empty.</div><div id="95" class="line none">   95          */</div><div id="96" class="line none">   96         char <a href="kernel/thread.h.html#246">dummy</a>;</div><div id="97" class="line none">   97 #endif</div><div id="98" class="line none">   98 /**</div><div id="99" class="line none">   99  * INTERNAL_HIDDEN @endcond</div><div id="100" class="line none">  100  */</div><div id="101" class="line none">  101 };</div><div id="102" class="line none">  102 </div><div id="103" class="line none">  103 /* There's a spinlock validation framework available when asserts are</div><div id="104" class="line none">  104  * enabled.  It adds a relatively hefty overhead (about 3k or so) to</div><div id="105" class="line none">  105  * kernel code size, don't use on platforms known to be small.</div><div id="106" class="line none">  106  */</div><div id="107" class="line none">  107 #ifdef CONFIG_SPIN_VALIDATE</div><div id="108" class="line none">  108 bool z_spin_lock_valid(struct <a href="spinlock.h.html#45">k_spinlock</a> *l);</div><div id="109" class="line none">  109 bool z_spin_unlock_valid(struct <a href="spinlock.h.html#45">k_spinlock</a> *l);</div><div id="110" class="line none">  110 void z_spin_lock_set_owner(struct <a href="spinlock.h.html#45">k_spinlock</a> *l);</div><div id="111" class="line none">  111 BUILD_ASSERT(CONFIG_MP_MAX_NUM_CPUS &lt;= 4, "Too many CPUs for mask");</div><div id="112" class="line none">  112 </div><div id="113" class="line none">  113 # ifdef CONFIG_KERNEL_COHERENCE</div><div id="114" class="line none">  114 bool z_spin_lock_mem_coherent(struct <a href="spinlock.h.html#45">k_spinlock</a> *l);</div><div id="115" class="line none">  115 # endif /* CONFIG_KERNEL_COHERENCE */</div><div id="116" class="line none">  116 </div><div id="117" class="line none">  117 #endif /* CONFIG_SPIN_VALIDATE */</div><div id="118" class="line none">  118 </div><div id="119" class="line none">  119 /**</div><div id="120" class="line none">  120  * @brief Spinlock key type</div><div id="121" class="line none">  121  *</div><div id="122" class="line none">  122  * This type defines a "key" value used by a spinlock implementation</div><div id="123" class="line none">  123  * to store the system interrupt state at the time of a call to</div><div id="124" class="line none">  124  * k_spin_lock().  It is expected to be passed to a matching</div><div id="125" class="line none">  125  * k_spin_unlock().</div><div id="126" class="line none">  126  *</div><div id="127" class="line none">  127  * This type is opaque and should not be inspected by application</div><div id="128" class="line none">  128  * code.</div><div id="129" class="line none">  129  */</div><div id="130" class="line none">  130 typedef struct <a href="spinlock.h.html#34">z_spinlock_key</a> <a href="spinlock.h.html#130">k_spinlock_key_t</a>;</div><div id="131" class="line none">  131 </div><div id="132" class="line none">  132 static ALWAYS_INLINE void <a href="spinlock.h.html#132">z_spinlock_validate_pre</a>(struct <a href="spinlock.h.html#45">k_spinlock</a> *l)</div><div id="133" class="line none">  133 {</div><div id="134" class="line none">  134         ARG_UNUSED(l);</div><div id="135" class="line none">  135 #ifdef CONFIG_SPIN_VALIDATE</div><div id="136" class="line none">  136         __ASSERT(z_spin_lock_valid(l), "Invalid spinlock %p", l);</div><div id="137" class="line none">  137 #ifdef CONFIG_KERNEL_COHERENCE</div><div id="138" class="line none">  138         __ASSERT_NO_MSG(z_spin_lock_mem_coherent(l));</div><div id="139" class="line none">  139 #endif</div><div id="140" class="line none">  140 #endif</div><div id="141" class="line none">  141 }</div><div id="142" class="line none">  142 </div><div id="143" class="line none">  143 static ALWAYS_INLINE void <a href="spinlock.h.html#143">z_spinlock_validate_post</a>(struct <a href="spinlock.h.html#45">k_spinlock</a> *l)</div><div id="144" class="line none">  144 {</div><div id="145" class="line none">  145         ARG_UNUSED(l);</div><div id="146" class="line none">  146 #ifdef CONFIG_SPIN_VALIDATE</div><div id="147" class="line none">  147         z_spin_lock_set_owner(l);</div><div id="148" class="line none">  148 #if defined(CONFIG_SPIN_LOCK_TIME_LIMIT) &amp;&amp; (CONFIG_SPIN_LOCK_TIME_LIMIT != 0)</div><div id="149" class="line none">  149         l-&gt;<a href="spinlock.h.html#77">lock_time</a> = sys_clock_cycle_get_32();</div><div id="150" class="line none">  150 #endif /* CONFIG_SPIN_LOCK_TIME_LIMIT */</div><div id="151" class="line none">  151 #endif /* CONFIG_SPIN_VALIDATE */</div><div id="152" class="line none">  152 }</div><div id="153" class="line none">  153 </div><div id="154" class="line none">  154 /**</div><div id="155" class="line none">  155  * @brief Lock a spinlock</div><div id="156" class="line none">  156  *</div><div id="157" class="line none">  157  * This routine locks the specified spinlock, returning a key handle</div><div id="158" class="line none">  158  * representing interrupt state needed at unlock time.  Upon</div><div id="159" class="line none">  159  * returning, the calling thread is guaranteed not to be suspended or</div><div id="160" class="line none">  160  * interrupted on its current CPU until it calls k_spin_unlock().  The</div><div id="161" class="line none">  161  * implementation guarantees mutual exclusion: exactly one thread on</div><div id="162" class="line none">  162  * one CPU will return from k_spin_lock() at a time.  Other CPUs</div><div id="163" class="line none">  163  * trying to acquire a lock already held by another CPU will enter an</div><div id="164" class="line none">  164  * implementation-defined busy loop ("spinning") until the lock is</div><div id="165" class="line none">  165  * released.</div><div id="166" class="line none">  166  *</div><div id="167" class="line none">  167  * Separate spin locks may be nested. It is legal to lock an</div><div id="168" class="line none">  168  * (unlocked) spin lock while holding a different lock.  Spin locks</div><div id="169" class="line none">  169  * are not recursive, however: an attempt to acquire a spin lock that</div><div id="170" class="line none">  170  * the CPU already holds will deadlock.</div><div id="171" class="line none">  171  *</div><div id="172" class="line none">  172  * In circumstances where only one CPU exists, the behavior of</div><div id="173" class="line none">  173  * k_spin_lock() remains as specified above, though obviously no</div><div id="174" class="line none">  174  * spinning will take place.  Implementations may be free to optimize</div><div id="175" class="line none">  175  * in uniprocessor contexts such that the locking reduces to an</div><div id="176" class="line none">  176  * interrupt mask operation.</div><div id="177" class="line none">  177  *</div><div id="178" class="line none">  178  * @param l A pointer to the spinlock to lock</div><div id="179" class="line none">  179  * @return A key value that must be passed to k_spin_unlock() when the</div><div id="180" class="line none">  180  *         lock is released.</div><div id="181" class="line none">  181  */</div><div id="182" class="line none">  182 static ALWAYS_INLINE <a href="spinlock.h.html#130">k_spinlock_key_t</a> <a href="spinlock.h.html#182">k_spin_lock</a>(struct <a href="spinlock.h.html#45">k_spinlock</a> *l)</div><div id="183" class="line none">  183 {</div><div id="184" class="line none">  184         ARG_UNUSED(l);</div><div id="185" class="line none">  185         <a href="spinlock.h.html#130">k_spinlock_key_t</a> k;</div><div id="186" class="line none">  186 </div><div id="187" class="line none">  187         /* Note that we need to use the underlying arch-specific lock</div><div id="188" class="line none">  188          * implementation.  The "irq_lock()" API in SMP context is</div><div id="189" class="line none">  189          * actually a wrapper for a global spinlock!</div><div id="190" class="line none">  190          */</div><div id="191" class="line none">  191         k.<a href="spinlock.h.html#35">key</a> = arch_irq_lock();</div><div id="192" class="line none">  192 </div><div id="193" class="line none">  193         <a href="spinlock.h.html#132">z_spinlock_validate_pre</a>(l);</div><div id="194" class="line none">  194 #ifdef CONFIG_SMP</div><div id="195" class="line none">  195 #ifdef CONFIG_TICKET_SPINLOCKS</div><div id="196" class="line none">  196         /*</div><div id="197" class="line none">  197          * Enqueue ourselves to the end of a spinlock waiters queue</div><div id="198" class="line none">  198          * receiving a ticket</div><div id="199" class="line none">  199          */</div><div id="200" class="line none">  200         <a href="sys/atomic_types.h.html#16">atomic_val_t</a> ticket = <a href="sys/atomic_builtin.h.html#49">atomic_inc</a>(&amp;l-&gt;<a href="spinlock.h.html#63">tail</a>);</div><div id="201" class="line none">  201         /* Spin until our ticket is served */</div><div id="202" class="line none">  202         while (<a href="sys/atomic_builtin.h.html#59">atomic_get</a>(&amp;l-&gt;<a href="kernel.h.html#2918">owner</a>) != ticket) {</div><div id="203" class="line none">  203                 arch_spin_relax();</div><div id="204" class="line none">  204         }</div><div id="205" class="line none">  205 #else</div><div id="206" class="line none">  206         while (!<a href="sys/atomic_builtin.h.html#23">atomic_cas</a>(&amp;l-&gt;locked, 0, 1)) {</div><div id="207" class="line none">  207                 arch_spin_relax();</div><div id="208" class="line none">  208         }</div><div id="209" class="line none">  209 #endif /* CONFIG_TICKET_SPINLOCKS */</div><div id="210" class="line none">  210 #endif /* CONFIG_SMP */</div><div id="211" class="line none">  211         <a href="spinlock.h.html#143">z_spinlock_validate_post</a>(l);</div><div id="212" class="line none">  212 </div><div id="213" class="line none">  213         return k;</div><div id="214" class="line none">  214 }</div><div id="215" class="line none">  215 </div><div id="216" class="line none">  216 /**</div><div id="217" class="line none">  217  * @brief Attempt to lock a spinlock</div><div id="218" class="line none">  218  *</div><div id="219" class="line none">  219  * This routine makes one attempt to lock @p l. If it is successful, then</div><div id="220" class="line none">  220  * it will store the key into @p k.</div><div id="221" class="line none">  221  *</div><div id="222" class="line none">  222  * @param[in] l A pointer to the spinlock to lock</div><div id="223" class="line none">  223  * @param[out] k A pointer to the spinlock key</div><div id="224" class="line none">  224  * @retval 0 on success</div><div id="225" class="line none">  225  * @retval -EBUSY if another thread holds the lock</div><div id="226" class="line none">  226  *</div><div id="227" class="line none">  227  * @see k_spin_lock</div><div id="228" class="line none">  228  * @see k_spin_unlock</div><div id="229" class="line none">  229  */</div><div id="230" class="line none">  230 static ALWAYS_INLINE int <a href="spinlock.h.html#230">k_spin_trylock</a>(struct <a href="spinlock.h.html#45">k_spinlock</a> *l, <a href="spinlock.h.html#130">k_spinlock_key_t</a> *k)</div><div id="231" class="line none">  231 {</div><div id="232" class="line none">  232         int <a href="spinlock.h.html#35">key</a> = arch_irq_lock();</div><div id="233" class="line none">  233 </div><div id="234" class="line none">  234         <a href="spinlock.h.html#132">z_spinlock_validate_pre</a>(l);</div><div id="235" class="line none">  235 #ifdef CONFIG_SMP</div><div id="236" class="line none">  236 #ifdef CONFIG_TICKET_SPINLOCKS</div><div id="237" class="line none">  237         /*</div><div id="238" class="line none">  238          * atomic_get and atomic_cas operations below are not executed</div><div id="239" class="line none">  239          * simultaneously.</div><div id="240" class="line none">  240          * So in theory k_spin_trylock can lock an already locked spinlock.</div><div id="241" class="line none">  241          * To reproduce this the following conditions should be met after we</div><div id="242" class="line none">  242          * executed atomic_get and before we executed atomic_cas:</div><div id="243" class="line none">  243          *</div><div id="244" class="line none">  244          * - spinlock needs to be taken 0xffff_..._ffff + 1 times</div><div id="245" class="line none">  245          * (which requires 0xffff_..._ffff number of CPUs, as k_spin_lock call</div><div id="246" class="line none">  246          * is blocking) or</div><div id="247" class="line none">  247          * - spinlock needs to be taken and released 0xffff_..._ffff times and</div><div id="248" class="line none">  248          * then taken again</div><div id="249" class="line none">  249          *</div><div id="250" class="line none">  250          * In real-life systems this is considered non-reproducible given that</div><div id="251" class="line none">  251          * required actions need to be done during this tiny window of several</div><div id="252" class="line none">  252          * CPU instructions (which execute with interrupt locked,</div><div id="253" class="line none">  253          * so no preemption can happen here)</div><div id="254" class="line none">  254          */</div><div id="255" class="line none">  255         <a href="sys/atomic_types.h.html#16">atomic_val_t</a> ticket_val = <a href="sys/atomic_builtin.h.html#59">atomic_get</a>(&amp;l-&gt;<a href="kernel.h.html#2918">owner</a>);</div><div id="256" class="line none">  256 </div><div id="257" class="line none">  257         if (!<a href="sys/atomic_builtin.h.html#23">atomic_cas</a>(&amp;l-&gt;<a href="spinlock.h.html#63">tail</a>, ticket_val, ticket_val + 1)) {</div><div id="258" class="line none">  258                 goto busy;</div><div id="259" class="line none">  259         }</div><div id="260" class="line none">  260 #else</div><div id="261" class="line none">  261         if (!<a href="sys/atomic_builtin.h.html#23">atomic_cas</a>(&amp;l-&gt;locked, 0, 1)) {</div><div id="262" class="line none">  262                 goto busy;</div><div id="263" class="line none">  263         }</div><div id="264" class="line none">  264 #endif /* CONFIG_TICKET_SPINLOCKS */</div><div id="265" class="line none">  265 #endif /* CONFIG_SMP */</div><div id="266" class="line none">  266         <a href="spinlock.h.html#143">z_spinlock_validate_post</a>(l);</div><div id="267" class="line none">  267 </div><div id="268" class="line none">  268         k-&gt;<a href="spinlock.h.html#35">key</a> = <a href="spinlock.h.html#35">key</a>;</div><div id="269" class="line none">  269 </div><div id="270" class="line none">  270         return 0;</div><div id="271" class="line none">  271 </div><div id="272" class="line none">  272 #ifdef CONFIG_SMP</div><div id="273" class="line none">  273 busy:</div><div id="274" class="line none">  274         arch_irq_unlock(<a href="spinlock.h.html#35">key</a>);</div><div id="275" class="line none">  275         return -EBUSY;</div><div id="276" class="line none">  276 #endif /* CONFIG_SMP */</div><div id="277" class="line none">  277 }</div><div id="278" class="line none">  278 </div><div id="279" class="line none">  279 /**</div><div id="280" class="line none">  280  * @brief Unlock a spin lock</div><div id="281" class="line none">  281  *</div><div id="282" class="line none">  282  * This releases a lock acquired by k_spin_lock().  After this</div><div id="283" class="line none">  283  * function is called, any CPU will be able to acquire the lock.  If</div><div id="284" class="line none">  284  * other CPUs are currently spinning inside k_spin_lock() waiting for</div><div id="285" class="line none">  285  * this lock, exactly one of them will return synchronously with the</div><div id="286" class="line none">  286  * lock held.</div><div id="287" class="line none">  287  *</div><div id="288" class="line none">  288  * Spin locks must be properly nested.  A call to k_spin_unlock() must</div><div id="289" class="line none">  289  * be made on the lock object most recently locked using</div><div id="290" class="line none">  290  * k_spin_lock(), using the key value that it returned.  Attempts to</div><div id="291" class="line none">  291  * unlock mis-nested locks, or to unlock locks that are not held, or</div><div id="292" class="line none">  292  * to passing a key parameter other than the one returned from</div><div id="293" class="line none">  293  * k_spin_lock(), are illegal.  When CONFIG_SPIN_VALIDATE is set, some</div><div id="294" class="line none">  294  * of these errors can be detected by the framework.</div><div id="295" class="line none">  295  *</div><div id="296" class="line none">  296  * @param l A pointer to the spinlock to release</div><div id="297" class="line none">  297  * @param key The value returned from k_spin_lock() when this lock was</div><div id="298" class="line none">  298  *        acquired</div><div id="299" class="line none">  299  */</div><div id="300" class="line none">  300 static ALWAYS_INLINE void <a href="spinlock.h.html#300">k_spin_unlock</a>(struct <a href="spinlock.h.html#45">k_spinlock</a> *l,</div><div id="301" class="line none">  301                                         <a href="spinlock.h.html#130">k_spinlock_key_t</a> <a href="spinlock.h.html#35">key</a>)</div><div id="302" class="line none">  302 {</div><div id="303" class="line none">  303         ARG_UNUSED(l);</div><div id="304" class="line none">  304 #ifdef CONFIG_SPIN_VALIDATE</div><div id="305" class="line none">  305         __ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);</div><div id="306" class="line none">  306 </div><div id="307" class="line none">  307 #if defined(CONFIG_SPIN_LOCK_TIME_LIMIT) &amp;&amp; (CONFIG_SPIN_LOCK_TIME_LIMIT != 0)</div><div id="308" class="line none">  308         uint32_t <a href="kernel/thread.h.html#173">delta</a> = sys_clock_cycle_get_32() - l-&gt;<a href="spinlock.h.html#77">lock_time</a>;</div><div id="309" class="line none">  309 </div><div id="310" class="line none">  310         __ASSERT(<a href="kernel/thread.h.html#173">delta</a> &lt; CONFIG_SPIN_LOCK_TIME_LIMIT,</div><div id="311" class="line none">  311                  "Spin lock %p held %u cycles, longer than limit of %u cycles",</div><div id="312" class="line none">  312                  l, <a href="kernel/thread.h.html#173">delta</a>, CONFIG_SPIN_LOCK_TIME_LIMIT);</div><div id="313" class="line none">  313 #endif /* CONFIG_SPIN_LOCK_TIME_LIMIT */</div><div id="314" class="line none">  314 #endif /* CONFIG_SPIN_VALIDATE */</div><div id="315" class="line none">  315 </div><div id="316" class="line none">  316 #ifdef CONFIG_SMP</div><div id="317" class="line none">  317 #ifdef CONFIG_TICKET_SPINLOCKS</div><div id="318" class="line none">  318         /* Give the spinlock to the next CPU in a FIFO */</div><div id="319" class="line none">  319         (void)<a href="sys/atomic_builtin.h.html#49">atomic_inc</a>(&amp;l-&gt;<a href="kernel.h.html#2918">owner</a>);</div><div id="320" class="line none">  320 #else</div><div id="321" class="line none">  321         /* Strictly we don't need atomic_clear() here (which is an</div><div id="322" class="line none">  322          * exchange operation that returns the old value).  We are always</div><div id="323" class="line none">  323          * setting a zero and (because we hold the lock) know the existing</div><div id="324" class="line none">  324          * state won't change due to a race.  But some architectures need</div><div id="325" class="line none">  325          * a memory barrier when used like this, and we don't have a</div><div id="326" class="line none">  326          * Zephyr framework for that.</div><div id="327" class="line none">  327          */</div><div id="328" class="line none">  328         (void)<a href="sys/atomic_builtin.h.html#83">atomic_clear</a>(&amp;l-&gt;locked);</div><div id="329" class="line none">  329 #endif /* CONFIG_TICKET_SPINLOCKS */</div><div id="330" class="line none">  330 #endif /* CONFIG_SMP */</div><div id="331" class="line none">  331         arch_irq_unlock(<a href="spinlock.h.html#35">key</a>.<a href="spinlock.h.html#35">key</a>);</div><div id="332" class="line none">  332 }</div><div id="333" class="line none">  333 </div><div id="334" class="line none">  334 /**</div><div id="335" class="line none">  335  * @cond INTERNAL_HIDDEN</div><div id="336" class="line none">  336  */</div><div id="337" class="line none">  337 </div><div id="338" class="line none">  338 #if defined(CONFIG_SMP) &amp;&amp; defined(CONFIG_TEST)</div><div id="339" class="line none">  339 /*</div><div id="340" class="line none">  340  * @brief Checks if spinlock is held by some CPU, including the local CPU.</div><div id="341" class="line none">  341  *              This API shouldn't be used outside the tests for spinlock</div><div id="342" class="line none">  342  *</div><div id="343" class="line none">  343  * @param l A pointer to the spinlock</div><div id="344" class="line none">  344  * @retval true - if spinlock is held by some CPU; false - otherwise</div><div id="345" class="line none">  345  */</div><div id="346" class="line none">  346 static ALWAYS_INLINE bool <a href="spinlock.h.html#346">z_spin_is_locked</a>(struct <a href="spinlock.h.html#45">k_spinlock</a> *l)</div><div id="347" class="line none">  347 {</div><div id="348" class="line none">  348 #ifdef CONFIG_TICKET_SPINLOCKS</div><div id="349" class="line none">  349         <a href="sys/atomic_types.h.html#16">atomic_val_t</a> ticket_val = <a href="sys/atomic_builtin.h.html#59">atomic_get</a>(&amp;l-&gt;<a href="kernel.h.html#2918">owner</a>);</div><div id="350" class="line none">  350 </div><div id="351" class="line none">  351         return !<a href="sys/atomic_builtin.h.html#23">atomic_cas</a>(&amp;l-&gt;<a href="spinlock.h.html#63">tail</a>, ticket_val, ticket_val);</div><div id="352" class="line none">  352 #else</div><div id="353" class="line none">  353         return l-&gt;locked;</div><div id="354" class="line none">  354 #endif /* CONFIG_TICKET_SPINLOCKS */</div><div id="355" class="line none">  355 }</div><div id="356" class="line none">  356 #endif /* defined(CONFIG_SMP) &amp;&amp; defined(CONFIG_TEST) */</div><div id="357" class="line none">  357 </div><div id="358" class="line none">  358 /* Internal function: releases the lock, but leaves local interrupts disabled */</div><div id="359" class="line none">  359 static ALWAYS_INLINE void <a href="spinlock.h.html#359">k_spin_release</a>(struct <a href="spinlock.h.html#45">k_spinlock</a> *l)</div><div id="360" class="line none">  360 {</div><div id="361" class="line none">  361         ARG_UNUSED(l);</div><div id="362" class="line none">  362 #ifdef CONFIG_SPIN_VALIDATE</div><div id="363" class="line none">  363         __ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);</div><div id="364" class="line none">  364 #endif</div><div id="365" class="line none">  365 #ifdef CONFIG_SMP</div><div id="366" class="line none">  366 #ifdef CONFIG_TICKET_SPINLOCKS</div><div id="367" class="line none">  367         (void)<a href="sys/atomic_builtin.h.html#49">atomic_inc</a>(&amp;l-&gt;<a href="kernel.h.html#2918">owner</a>);</div><div id="368" class="line none">  368 #else</div><div id="369" class="line none">  369         (void)<a href="sys/atomic_builtin.h.html#83">atomic_clear</a>(&amp;l-&gt;locked);</div><div id="370" class="line none">  370 #endif /* CONFIG_TICKET_SPINLOCKS */</div><div id="371" class="line none">  371 #endif /* CONFIG_SMP */</div><div id="372" class="line none">  372 }</div><div id="373" class="line none">  373 </div><div id="374" class="line none">  374 #if defined(CONFIG_SPIN_VALIDATE) &amp;&amp; defined(__GNUC__)</div><div id="375" class="line none">  375 static ALWAYS_INLINE void <a href="spinlock.h.html#375">z_spin_onexit</a>(__maybe_unused <a href="spinlock.h.html#130">k_spinlock_key_t</a> *k)</div><div id="376" class="line none">  376 {</div><div id="377" class="line none">  377         __ASSERT(k-&gt;<a href="spinlock.h.html#35">key</a>, "K_SPINLOCK exited with goto, break or return, "</div><div id="378" class="line none">  378                          "use K_SPINLOCK_BREAK instead.");</div><div id="379" class="line none">  379 }</div><div id="380" class="line none">  380 #define <a href="spinlock.h.html#380">K_SPINLOCK_ONEXIT</a> __attribute__((__cleanup__(<a href="spinlock.h.html#375">z_spin_onexit</a>)))</div><div id="381" class="line none">  381 #else</div><div id="382" class="line none">  382 #define <a href="spinlock.h.html#380">K_SPINLOCK_ONEXIT</a></div><div id="383" class="line none">  383 #endif</div><div id="384" class="line none">  384 </div><div id="385" class="line none">  385 /**</div><div id="386" class="line none">  386  * INTERNAL_HIDDEN @endcond</div><div id="387" class="line none">  387  */</div><div id="388" class="line none">  388 </div><div id="389" class="line none">  389 /**</div><div id="390" class="line none">  390  * @brief Leaves a code block guarded with @ref K_SPINLOCK after releasing the</div><div id="391" class="line none">  391  * lock.</div><div id="392" class="line none">  392  *</div><div id="393" class="line none">  393  * See @ref K_SPINLOCK for details.</div><div id="394" class="line none">  394  */</div><div id="395" class="line none">  395 #define <a href="spinlock.h.html#395">K_SPINLOCK_BREAK</a> continue</div><div id="396" class="line none">  396 </div><div id="397" class="line none">  397 /**</div><div id="398" class="line none">  398  * @brief Guards a code block with the given spinlock, automatically acquiring</div><div id="399" class="line none">  399  * the lock before executing the code block. The lock will be released either</div><div id="400" class="line none">  400  * when reaching the end of the code block or when leaving the block with</div><div id="401" class="line none">  401  * @ref K_SPINLOCK_BREAK.</div><div id="402" class="line none">  402  *</div><div id="403" class="line none">  403  * @details Example usage:</div><div id="404" class="line none">  404  *</div><div id="405" class="line none">  405  * @code{.c}</div><div id="406" class="line none">  406  * K_SPINLOCK(&amp;mylock) {</div><div id="407" class="line none">  407  *</div><div id="408" class="line none">  408  *   ...execute statements with the lock held...</div><div id="409" class="line none">  409  *</div><div id="410" class="line none">  410  *   if (some_condition) {</div><div id="411" class="line none">  411  *     ...release the lock and leave the guarded section prematurely:</div><div id="412" class="line none">  412  *     K_SPINLOCK_BREAK;</div><div id="413" class="line none">  413  *   }</div><div id="414" class="line none">  414  *</div><div id="415" class="line none">  415  *   ...execute statements with the lock held...</div><div id="416" class="line none">  416  *</div><div id="417" class="line none">  417  * }</div><div id="418" class="line none">  418  * @endcode</div><div id="419" class="line none">  419  *</div><div id="420" class="line none">  420  * Behind the scenes this pattern expands to a for-loop whose body is executed</div><div id="421" class="line none">  421  * exactly once:</div><div id="422" class="line none">  422  *</div><div id="423" class="line none">  423  * @code{.c}</div><div id="424" class="line none">  424  * for (k_spinlock_key_t key = k_spin_lock(&amp;mylock); ...; k_spin_unlock(&amp;mylock, key)) {</div><div id="425" class="line none">  425  *     ...</div><div id="426" class="line none">  426  * }</div><div id="427" class="line none">  427  * @endcode</div><div id="428" class="line none">  428  *</div><div id="429" class="line none">  429  * @warning The code block must execute to its end or be left by calling</div><div id="430" class="line none">  430  * @ref K_SPINLOCK_BREAK. Otherwise, e.g. if exiting the block with a break,</div><div id="431" class="line none">  431  * goto or return statement, the spinlock will not be released on exit.</div><div id="432" class="line none">  432  *</div><div id="433" class="line none">  433  * @note In user mode the spinlock must be placed in memory accessible to the</div><div id="434" class="line none">  434  * application, see @ref K_APP_DMEM and @ref K_APP_BMEM macros for details.</div><div id="435" class="line none">  435  *</div><div id="436" class="line none">  436  * @param lck Spinlock used to guard the enclosed code block.</div><div id="437" class="line none">  437  */</div><div id="438" class="line none">  438 #define <a href="spinlock.h.html#438">K_SPINLOCK</a>(lck)                                                                            \</div><div id="439" class="line none">  439         for (<a href="spinlock.h.html#130">k_spinlock_key_t</a> __i <a href="spinlock.h.html#380">K_SPINLOCK_ONEXIT</a> = {}, __key = <a href="spinlock.h.html#182">k_spin_lock</a>(lck); !__i.<a href="spinlock.h.html#35">key</a>;      \</div><div id="440" class="line none">  440              <a href="spinlock.h.html#300">k_spin_unlock</a>((lck), __key), __i.<a href="spinlock.h.html#35">key</a> = 1)</div><div id="441" class="line none">  441 </div><div id="442" class="line none">  442 /** @} */</div><div id="443" class="line none">  443 </div><div id="444" class="line none">  444 #ifdef __cplusplus</div><div id="445" class="line none">  445 }</div><div id="446" class="line none">  446 #endif</div><div id="447" class="line none">  447 </div><div id="448" class="line none">  448 #endif /* ZEPHYR_INCLUDE_SPINLOCK_H_ */</div>
</div>
</body>
</html>
